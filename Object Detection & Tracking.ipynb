{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd24e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb386e",
   "metadata": {},
   "source": [
    "# Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54c92793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO class labels\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c0103",
   "metadata": {},
   "source": [
    "# Model Loading and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fc8dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ecf87",
   "metadata": {},
   "source": [
    "# Object Tracking using Optical FLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d74935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Initialize variables for optical flow\n",
    "old_frame = None\n",
    "trackers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04307bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Intersection over Union (IoU)\n",
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    \n",
    "    # Calculate coordinates of intersection area\n",
    "    xi1 = max(x1, x2)\n",
    "    yi1 = max(y1, y2)\n",
    "    xi2 = min(x1 + w1, x2 + w2)\n",
    "    yi2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    # Calculate area of intersection rectangle\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "\n",
    "    # Calculate area of both bounding boxes\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62173cd5",
   "metadata": {},
   "source": [
    "# Real Time Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ab636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)  \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Object detection using YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Lists to store detected objects\n",
    "    detected_boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    # Process each detection from YOLO output\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.5:  # Filter out weak detections\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                detected_boxes.append((x, y, w, h))\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Update optical flow trackers only if there are existing trackers and new detections\n",
    "    if old_frame is not None and trackers and detected_boxes:\n",
    "        # Convert frames to grayscale for optical flow\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        for tracker in trackers:\n",
    "            x, y, w, h = tracker[\"bbox\"]\n",
    "            roi = old_gray[y:y+h, x:x+w]\n",
    "            p1, _, _ = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, np.array([[x + w // 2, y + h // 2]], dtype=np.float32), None, **lk_params)\n",
    "            p1 = p1.reshape(-1, 2)\n",
    "\n",
    "            # Update bounding box based on optical flow\n",
    "            new_x = int(np.median(p1[:, 0]) - w // 2)\n",
    "            new_y = int(np.median(p1[:, 1]) - h // 2)\n",
    "            tracker[\"bbox\"] = (new_x, new_y, w, h)\n",
    "\n",
    "    # Initialize new trackers for new detections or update existing ones\n",
    "    updated_trackers = []\n",
    "    for box, confidence, class_id in zip(detected_boxes, confidences, class_ids):\n",
    "        matched = False\n",
    "        for tracker in trackers:\n",
    "            iou = calculate_iou(tracker[\"bbox\"], box)\n",
    "            if iou > 0.3:  # IoU threshold to consider it as the same object\n",
    "                # Update existing tracker\n",
    "                tracker[\"bbox\"] = box\n",
    "                tracker[\"confidence\"] = confidence\n",
    "                tracker[\"class_id\"] = class_id\n",
    "                updated_trackers.append(tracker)\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "        if not matched:\n",
    "            # Create new tracker\n",
    "            updated_trackers.append({\"bbox\": box, \"confidence\": confidence, \"class_id\": class_id})\n",
    "\n",
    "    trackers = updated_trackers\n",
    "\n",
    "    # Store current frame for the next iteration\n",
    "    old_frame = frame.copy()\n",
    "\n",
    "    # Display bounding boxes and labels from YOLO\n",
    "    for tracker in trackers:\n",
    "        x, y, w, h = tracker[\"bbox\"]\n",
    "        label = str(classes[tracker[\"class_id\"]])\n",
    "        color = (0, 255, 0)  # Green color for bounding box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(frame, f\"{label} {tracker['confidence']:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Display optical flow tracking with red dot\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        cv2.circle(frame, (center_x, center_y), 5, (0, 0, 255), -1)  # Red dot for object center\n",
    "\n",
    "    # Visualization\n",
    "    cv2.imshow(\"Object Detection and Tracking with IoU\", frame)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a2ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
